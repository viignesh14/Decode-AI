// ============================================================
// Decode AI â€” Backend Proxy Server
// Chrome Extension â†’ THIS SERVER â†’ Gemini API
//
// The API key NEVER leaves this server.
// ============================================================

require('dotenv').config();
const express = require('express');
const cors = require('cors');
const { GoogleGenerativeAI } = require('@google/generative-ai');

const app = express();
const PORT = process.env.PORT || 3000;

// â”€â”€ Gemini Client â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);

// â”€â”€ Valid models â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const VALID_MODELS = new Set([
    'gemini-2.5-flash',
    'gemini-2.5-pro',
    'gemini-2.0-flash',
    'gemini-2.0-flash-exp'
]);
const DEFAULT_MODEL = 'gemini-2.5-flash';

// â”€â”€ Middleware â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app.use(express.json({ limit: '100kb' }));  // Limit request body size

// CORS â€” allow Chrome extension origins (chrome-extension://)
app.use(cors({
    origin: (origin, callback) => {
        // Allow: Chrome extensions, localhost dev, and configured ALLOWED_ORIGIN
        if (
            !origin ||
            origin.startsWith('chrome-extension://') ||
            origin.startsWith('http://localhost') ||
            origin === process.env.ALLOWED_ORIGIN
        ) {
            callback(null, true);
        } else {
            callback(new Error('Not allowed by CORS'));
        }
    },
    methods: ['POST', 'GET'],
    allowedHeaders: ['Content-Type']
}));

// â”€â”€ Health check endpoint â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app.get('/health', (req, res) => {
    res.json({ status: 'ok', service: 'Decode AI Backend', version: '1.0.0' });
});

// â”€â”€ Main Generate Endpoint â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// POST /generate
// Body: { prompt: string, model?: string }
// Response: { result: string } or { error: string }
app.post('/generate', async (req, res) => {
    const { prompt, model: requestedModel } = req.body;

    // Validate request
    if (!prompt || typeof prompt !== 'string') {
        return res.status(400).json({ error: 'Missing or invalid "prompt" field.' });
    }
    if (prompt.length > 50000) {
        return res.status(400).json({ error: 'Prompt too long (max 50,000 characters).' });
    }

    // Resolve model â€” fall back to default if invalid/missing
    const model = VALID_MODELS.has(requestedModel) ? requestedModel : DEFAULT_MODEL;

    try {
        const geminiModel = genAI.getGenerativeModel({
            model,
            safetySettings: [
                { category: 'HARM_CATEGORY_HARASSMENT', threshold: 'BLOCK_NONE' },
                { category: 'HARM_CATEGORY_HATE_SPEECH', threshold: 'BLOCK_NONE' },
                { category: 'HARM_CATEGORY_SEXUALLY_EXPLICIT', threshold: 'BLOCK_NONE' },
                { category: 'HARM_CATEGORY_DANGEROUS_CONTENT', threshold: 'BLOCK_NONE' }
            ],
            generationConfig: {
                temperature: 0.7,
                topK: 40,
                topP: 0.95,
                maxOutputTokens: 8192
            }
        });

        const result = await geminiModel.generateContent(prompt);
        const response = await result.response;
        const text = response.text();

        if (!text) {
            return res.status(500).json({ error: 'No response generated by the AI.' });
        }

        return res.json({ result: text });

    } catch (err) {
        console.error('[Decode AI] Gemini error:', err.message);

        // Map Google API errors to friendly messages
        if (err.message?.includes('429') || err.status === 429) {
            return res.status(429).json({ error: 'Too many requests. Please wait a moment and try again.' });
        }
        if (err.message?.includes('API_KEY') || err.status === 403) {
            return res.status(403).json({ error: 'Server API key error. Contact support.' });
        }
        if (err.message?.includes('SAFETY')) {
            return res.status(400).json({ error: 'Response blocked by safety filters.' });
        }

        return res.status(500).json({ error: `AI Error: ${err.message}` });
    }
});

// â”€â”€ Start Server â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app.listen(PORT, '0.0.0.0', () => {
    console.log(`\nğŸš€ Decode AI Backend running on http://0.0.0.0:${PORT}`);
    console.log(`   Health check: http://localhost:${PORT}/health`);
    console.log(`   Generate:     POST http://localhost:${PORT}/generate`);
    console.log(`\nğŸ” API key loaded: ${process.env.GEMINI_API_KEY ? 'âœ… Yes' : 'âŒ NOT FOUND â€” check .env'}`);
    console.log(`   Model default: ${DEFAULT_MODEL}\n`);
});
